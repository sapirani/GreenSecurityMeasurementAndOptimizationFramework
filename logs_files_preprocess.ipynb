{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "output_file_path = r\"../../Downloads/merged_file\"\n",
    "\n",
    "# Traverse through all the subfolders and extract the compressed files\n",
    "extracted_files = []\n",
    "for subfolder_name in os.listdir(r\"../../Downloads/RAWLOGS_august/RAWLOGS/\"):\n",
    "    subfolder_path = os.path.join(r\"../../Downloads/RAWLOGS_august/RAWLOGS\", subfolder_name)\n",
    "    for subfolder2_name in os.listdir(subfolder_path):\n",
    "        subfolder2_path = os.path.join(subfolder_path, subfolder2_name)\n",
    "        for file_name in os.listdir(subfolder2_path):\n",
    "            if file_name.endswith(\".gz\"):\n",
    "                file_path = os.path.join(subfolder2_path, file_name)\n",
    "                with gzip.open(file_path, 'rb') as f:\n",
    "                    file_content = json.loads(f.read().decode('utf-8'))\n",
    "                    for log in file_content[\"Records\"]:                \n",
    "                    #     dt = datetime.datetime.strptime(log['eventTime'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                    #     # Convert the datetime to UTC timezone\n",
    "                    #     utc_dt = dt.astimezone(pytz.utc)\n",
    "                    #     # Convert the UTC datetime to UTC+3 timezone\n",
    "                    #     utc3_dt = utc_dt.astimezone(pytz.timezone('Asia/Jerusalem'))\n",
    "                    #     # Print the converted datetime string\n",
    "                    #     log['eventTime'] = utc3_dt.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n",
    "                    #     # log['eventTime'] = datetime.datetime.strptime(log['eventTime'],\"%Y-%m-%dT%H:%M:%SZ\").replace(tzinfo=datetime.timezone(datetime.timedelta(hours=+3), 'Jerusalem')).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "                        \n",
    "                        dt = datetime.datetime.strptime(log['eventTime'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "                        # Convert the datetime object to the desired format\n",
    "                        log['eventTime'] = dt.strftime('%Y-%m-%d %H:%M:%S,%f')[:-3]\n",
    "                    extracted_files += file_content[\"Records\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = r\"../../Downloads/merged_file\"\n",
    "with open(output_file_path+\".json\", 'w') as f:\n",
    "        for i, record in enumerate(extracted_files):\n",
    "            json.dump(record, f)\n",
    "            if i != len(extracted_files) - 1:\n",
    "                f.write(\",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the merged JSON file with the independent entries structure\n",
    "for j in range(8):\n",
    "    with open(output_file_path+str(j)+\".json\", 'w') as f:\n",
    "        curr = extracted_files[int(j/8*len(extracted_files)):int((j+1)/8*len(extracted_files))]\n",
    "        for i, record in enumerate(curr):\n",
    "            json.dump(record, f)\n",
    "            if i != len(curr) - 1:\n",
    "                f.write(\",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "file_path  = r\"C:\\Program Files\\Splunk\\etc\\apps\\SA-Eventgen\\samples\\cloudtrail_behavioural_detections.json\"\n",
    "logs = []\n",
    "for line in open(file_path, 'r'):\n",
    "    log = json.loads(line)        \n",
    "    dt = datetime.datetime.strptime(log['eventTime'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    # Convert the datetime object to the desired format\n",
    "    log['eventTime'] = dt.strftime('%Y-%m-%d %H:%M:%S,%f')[:-3]\n",
    "    logs.append(log)\n",
    "with open(r\"C:\\Program Files\\Splunk\\etc\\apps\\SA-Eventgen\\samples\\cloudtrail_behavioural_detections_2.json\", 'w') as f:\n",
    "    for i, record in enumerate(logs):\n",
    "            json.dump(record, f)\n",
    "            if i != len(logs) - 1:\n",
    "                f.write(\",\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
